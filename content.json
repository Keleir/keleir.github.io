[{"title":"Prometheus Service Discovery","date":"2018-03-27T08:31:33.000Z","path":"2018/03/27/prometheus-service-discovery/","text":"Prometheus Service DiscoveryService Discovery Build-in Service Discovery JSON file Service Discovery Consul Service Discovery (1) Build-in Discovery prometheus/retrieval/targetmanager.go Sources() []string，返回当前provider的标示。target manager将返回的string作为target group的ID Run(up chan&lt;- config.TargetGroup, done &lt;-chan struct{})，启动target provider。provider会将最新的target group信息输出到up这个channel中，以通知target manager。 prometheus/config/config.go Targets，会被prometheus解析，用于获得target metrics的访问信息，会被添加到metrics记录上； Labels，普通的label，会被添加到metrics记录上； Source，等同于ID。 Kubernetes sd_config1234567891011121314- job_name: kubelets scrape_interval: 1m scrape_timeout: 10s metrics_path: /metrics scheme: https kubernetes_sd_configs: - api_server: null role: node namespaces: names: [] bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt insecure_skip_verify: true (2) JSON file service discovery12345scrape_configs: - job_name: 'dummy' # This is a default value, it is mandatory. file_sd_configs: - files: - targets.json 12345- job_name: 'test' scrape_interval: '1s' file_sd_configs: - files: - 'sd_configs/*.json' 12345678910[ &#123; \"targets\": [ \"localhost:10003\" ], \"labels\": &#123; \"job\": \"ExporterInc\" &#125; &#125;] 1INFO[0000] Starting target manager... source=\"targetmanager.go:63\" (3) Consul Discovery12345678910scrape_configs: - job_name: consul consul_sd_configs: - server: 'localhost:8500' relabel_configs: - source_labels: [__meta_consul_tags] regex: .*,monitor,.* action: keep - source_labels: [__meta_consul_service] target_label: service With ACL Setting123456789101112131415scrape_configs: - job_name: 'consul_sd' consul_sd_configs: - server: 'localhost:8500' token: '63c7ce81-1e3b-9081-dff5-d91ede002ceb' relabel_configs: - source_labels: ['__meta_consul_service'] regex: prometheus\\-(.+) replacement: '$&#123;1&#125;' target_label: 'job' - source_labels: ['__meta_consul_service'] regex: consul action: drop - source_labels: ['__meta_consul_node'] target_label: 'node' snmp_config123456789101112131415161718192021222324252627282930313233- job_name: snmp_exporter-hwswitch20232 params: module: - hwswitch scrape_interval: 1m scrape_timeout: 10s metrics_path: /snmp scheme: http static_configs: - targets: - 10.200.3.233 labels: business: 6f289f7e-e1c7-4e9a-b217-5580cd61f397 sub_business: d185b50e-cba2-40b8-8901-1181ecc63ad3 relabel_configs: - source_labels: [__address__] separator: ; regex: (.*) target_label: __param_target replacement: $1 action: replace - source_labels: [__param_target] separator: ; regex: (.*) target_label: instance replacement: $1 action: replace - source_labels: [] separator: ; regex: (.*) target_label: __address__ replacement: 127.0.0.1:20232 action: replace snmp file_sd_config: 1234567891011121314151617181920212223242526272829303132- job_name: snmp_exporter params: module: - hwswitch scrape_interval: 1m scrape_timeout: 10s metrics_path: /snmp scheme: http file_sd_configs: - files: - 'snmp_config/*.json' relabel_configs: - source_labels: [__address__] separator: ; regex: (.*) target_label: __param_target replacement: $1 action: replace - source_labels: [__param_target] separator: ; regex: (.*) target_label: instance replacement: $1 action: replace - source_labels: [] separator: ; regex: (.*) target_label: __address__ replacement: 10.200.0.185:20232 action: replace snmp.json 12345678[ &#123; \"targets\": [ \"10.200.3.233\" ], \"labels\": &#123; \"job\": \"snmp_h3c\" &#125; &#125;] Refers Prometheus对Swarm的服务发现插件 Finding Consul services to monitor with Prometheus Using JSON file service discovery with Prometheus","tags":[{"name":"prometheus","slug":"prometheus","permalink":"http://keleir.github.io/tags/prometheus/"}]},{"title":"Prometheus Storage","date":"2018-02-27T07:59:47.000Z","path":"2018/02/27/prometheus-storage/","text":"Prometheus Storage On average, Prometheus uses only around 1-2 bytes per sample. Thus, to plan the capacity of a Prometheus server, you can use the rough formula: 1needed_disk_space = retention_time_seconds * ingested_samples_per_second * bytes_per_sample Concepts chunks this data together in chunks of constant size (1024 bytes) keeps all the currently used (incomplete) chunks in memory batch up write operations to store chunks on disk OptimizeMemory Options storage.local.memory-chunks how many chunks can Prometheus keep in memory. Remember, it’s the number of chunks, not the size in bytes.Suggested value: &lt;total memory in bytes&gt; / 1024 / 6. storage.local.max-chunks-to-persist how many chunks can be waiting to be written to the disk.Suggested value: memory-chunks / 2 The rushed mode When the number of chunks in memory, waiting to be persisted to disk, grows too much, Prometheus enters the rushed mode and speed up persisting chunks. Prometheus calculate an urgency score, as the number of chunks waiting for persistence in relation to max-chunks-to-persist and on how much the number of chunks in memory exceeds the memory-chunks. urgency_score &gt; 0.8: Enter Rushed Mode urgency_score &lt; 0.7: Leave Rushed Mode SnapshotSnapshot API Prometheus V2.0 提供了snapshot机制用于TSDB Backend数据备份, 创建快照API开启方式: --web.enable-admin-api 12345678$ curl -XPOST http://localhost:9090/api/v2/admin/tsdb/snapshot$ curl -X POST http://prometheus.in.dataengine.com/api/v2/admin/tsdb/snapshot&#123; \"name\": \"2017-12-05T06:42:03Z-32d47b4db4c3e108\"&#125; Data Directory123456789101112131415161718data├── 01C0JGQ905RK2ZZCQS8F7VSNV7│ ├── chunks│ ├── index│ ├── meta.json│ └── tombstones├── 01C0JQJTVZ6JC5MQJFSG145979│ ├── chunks│ ├── index│ ├── meta.json│ └── tombstones├── lock├── snapshots│ ├── 2017-12-05T06:42:03Z-32d47b4db4c3e108│ └── 2017-12-05T06:42:44Z-6be0c2980c1989c5└── wal ├── 000001 └── 000002 Snapshot Directory12345672017-12-05T06:42:44Z-6be0c2980c1989c5└── 01C0K07PSNB97D6TXJQ7YE9ST1 ├── chunks │ └── 000001 ├── index ├── meta.json └── tombstones meta.json 1234567891011121314151617&#123; \"version\": 1, \"ulid\": \"01C0JPHXJ8BBG194HPNZFP7AR7\", \"minTime\": 1512446400000, \"maxTime\": 1512456122548, \"stats\": &#123; \"numSamples\": 321304, \"numSeries\": 604, \"numChunks\": 3020 &#125;, \"compaction\": &#123; \"level\": 1, \"sources\": [ \"01C0JPHXJ8BBG194HPNZFP7AR7\" ] &#125;&#125; maxTime - minTime = storage.tsdb.min-block-duration (default: 2h) meta.json 文件存储了 series 起止时间 / metircs 数量 / block 目录名称; 每个snapshot 由一个或多个 Chunk Block 组成, 这些Block 共同存储了Prometheus TSDB 的全量数据; Chunk Block 生成的数量由 storage.tsdb.min-block-duration 和 storage.tsdb.max-block-duration 控制; 12caller=compact.go:361 component=tsdb msg=\"compact blocks\" count=1mint=1512532800000 maxt=1512539893781 Prometheus Version: 1.7.01time=\"2017-11-20T03:58:23+08:00\" level=error msg=\"Storage needs throttling. Scrapes and rule evaluations will be skipped.\" chunksToPersist=92938 memoryChunks=493334 source=\"storage.go:1007\" urgencyScore=1 Refers KubeCon 2017 - Prometheus Takeaways How much RAM does my Prometheus need for ingestion? Writing a Time Series Database from Scratch Continuous Improvement in Monitoring with Prometheus 2.0 剖析Prometheus的内部存储机制 LevelDB 实现分析 Research Prometheus WAL Log Chunk Data Snapshot","tags":[{"name":"prometheus","slug":"prometheus","permalink":"http://keleir.github.io/tags/prometheus/"}]},{"title":"Prometheus in Practice","date":"2018-01-27T07:46:35.000Z","path":"2018/01/27/prometheus-in-practice/","text":"Prometheus docker-composer docker-compose.yml 12345678910version: '2'services: prometheus: image: prom/prometheus:latest volumes: - ./prometheus.yml:/etc/prometheus/prometheus.yml command: - '-config.file=/etc/prometheus/prometheus.yml' ports: - '9090:9090' prometheus.yml 12345678global: scrape_interval: 5s external_labels: monitor: 'my-monitor'scrape_configs: - job_name: prometheus static_configs: - targets: ['localhost:9090'] 1docker-compose up http://localhost:9090/statushttp://localhost:9090/metrics HTTP API http://prometheus.in.dataengine.com/api/v1/query?query=node_cpu{instance=&quot;bj-rc-dptd-bluesharp-app-1-v-test-1:19000&quot;,mode=&quot;idle&quot;} http://prometheus.in.dataengine.com/api/v1/query?query=irate(node_network_transmit_packets{device=%22lo%22,instance=%22bj-rc-devops-sftp-v-online-1:19000%22,job=%22node_exporter%22}[5m]) 1234567891011121314&#123; \"status\": \"success\", \"data\": &#123; \"resultType\": \"vector\", \"result\": [&#123; \"metric\": &#123; \"device\": \"lo\", \"instance\": \"bj-rc-devops-sftp-v-online-1:19000\", \"job\": \"node_exporter\" &#125;, \"value\": [1507878801.765, \"0\"] &#125;] &#125;&#125; “value”: [ 1507878801.765, “0” ]“value”: [ 当前时间戳，当前值 ] Query Series Query Series by label GET /api/v1/series?match[]={job=jboName} http://prometheus.in.dataengine.com/api/v1/series?match[]={job=&quot;zookeeper_exporter&quot;} 1234567891011121314151617&#123; \"status\": \"success\", \"data\": [ &#123; \"__name__\": \"zk_znode_count\", \"exported_instance\": \"10.200.3.88:2181\", \"instance\": \"10.200.0.192:9120\", \"job\": \"zookeeper_exporter\" &#125;, &#123; \"__name__\": \"zookeeper_MaxClientCnxnsPerHost\", \"instance\": \"10.200.10.42:7071\", \"job\": \"zookeeper_exporter\", \"replicaId\": \"1\" &#125; ]&#125; Query labels http://prometheus.in.dataengine.com/api/v1/label/job/values12345678&#123; \"status\": \"success\", \"data\": [ \"apache_exporter\", \"ceph_exporter\", \"zookeeper_exporter\" ]&#125; Query Range curl -s ‘http://prometheus.in.dataengine.com/api/v1/query_range?query=up&amp;start=2017-11-01T20:10:30.781Z&amp;end=2017-11-08T20:11:00.781Z&amp;step=1h‘ | jq API List1http://prometheus.in.dataengine.com/api/v1/label/__name__/values Node Exporter docker-compose.yml 1234567891011121314version: '2'services: prometheus: image: prom/prometheus:latest volumes: - ./prometheus.yml:/etc/prometheus/prometheus.yml command: - '-config.file=/etc/prometheus/prometheus.yml' ports: - '9090:9090' node-exporter: image: prom/node-exporter:latest ports: - '9100:9100' prometheus.yml 1234567891011global: scrape_interval: 5s external_labels: monitor: 'my-monitor'scrape_configs: - job_name: prometheus static_configs: - targets: ['localhost:9090'] - job_name: 'node-exporter' static_configs: - targets: ['node-exporter:9100'] Reload Config(1) POST1curl -i -v -X POST -H 'Accept: application/json; indent=4' http://localhost:9090/-/reload (2) SIGHUP1kill -HUP pid Push Gateway $ cat docker-compose.yml 123456version: '2'services: pushgateway: image: prom/pushgateway:latest ports: - \"9091:9091\" $ cat prometheus.yml123- job_name: 'pushgateway' static_configs: - targets: ['10.200.3.98:9091'] Push Metrics/metrics/job/&lt;JOBNAME&gt;{/&lt;LABEL_NAME&gt;/&lt;LABEL_VALUE&gt;} 123# Send metrics to pushgatewaycurl -s http://$EXPORTER_ADDR/$EXPORTER_METRIC | \\ curl --data-binary @- http://$PGW_ADDR/metrics/job/$PGW_JOB/instance/$PGW_INSTANCE e.g: 12curl -s 10.200.3.98:9100/metrics | curl --data-binary @- http://10.200.3.98:9091/metrics/job/node_exporter/instance/\"10.200.3.98:9100\" Add label when push metrics12curl -s 10.200.3.98:9100/metrics | curl --data-binary @- http://10.200.3.98:9091/metrics/job/node_exporter/instance/\"10.200.3.98:9100\"/group/kallen/platform/openstack/service/mysql 1echo \"kallen_dev_metric 20\" | curl --data-binary @- http://10.205.16.15:9091/metrics/job/kallen_exporter/instance/10.205.16.15:8888 -v 12345678910111213141516171819echo \"kallen_dev_metric 20\" | curl --data-binary @- http://10.205.16.15:9091/metrics/job/kallen_exporter/instance/10.205.16.15:8888 -v* About to connect() to 10.205.16.15 port 9091 (#0)* Trying 10.205.16.15...* Connected to 10.205.16.15 (10.205.16.15) port 9091 (#0)&gt; POST /metrics/job/kallen_exporter/instance/10.205.16.15:8888 HTTP/1.1&gt; User-Agent: curl/7.29.0&gt; Host: 10.205.16.15:9091&gt; Accept: */*&gt; Content-Length: 21&gt; Content-Type: application/x-www-form-urlencoded&gt; * upload completely sent off: 21 out of 21 bytes&lt; HTTP/1.1 202 Accepted&lt; Date: Fri, 03 Nov 2017 10:01:54 GMT&lt; Content-Length: 0&lt; Content-Type: text/plain; charset=utf-8&lt; * Connection #0 to host 10.205.16.15 left intact Alert Manager prometheus.yml 12345678alerting: alertmanagers: - scheme: https static_configs: - targets: - \"1.2.3.4:9093\" - \"1.2.3.5:9093\" - \"1.2.3.6:9093\" AlertManager API http://10.200.3.98:9093/api/v1/alerts http://10.200.3.98:9093/api/v1/alerts/groups http://10.200.3.98:9093/api/v1/status http://10.200.3.98:9093/api/v1/silences Receivers123456route: group_by: [ alertname ] group_wait: 30s group_interval: 5m repeat_interval: 2h receiver: 'slacker' Multiple Receiver 1234567891011121314151617181920route: group_by: [ alertname ] group_wait: 30s group_interval: 5m repeat_interval: 2h receiver: 'slacker' routes: - match_re: job: .+ receiver: 'alerta'receivers: - name: 'alerta' webhook_configs: - url: 'http://10.203.16.119:8181/api/webhooks/prometheus' send_resolved: true - name: slacker ... AlertManager HA alertmanager123456789101112# On a machine named \"am-1\":wget https://github.com/prometheus/alertmanager/releases/download/v0.7.1/alertmanager-0.7.1.linux-amd64.tar.gztar -xzf alertmanager-*.linux-amd64.tar.gzcd alertmanager-*./alertmanager -config.file simple.yml -mesh.peer=am-2:6783# On a machine named \"am-2\":wget https://github.com/prometheus/alertmanager/releases/download/v0.7.1/alertmanager-0.7.1.linux-amd64.tar.gztar -xzf alertmanager-*.linux-amd64.tar.gzcd alertmanager-*./alertmanager -config.file simple.yml -mesh.peer=am-1:6783 prometheus.yml1234alerting: alertmanagers: - static_configs: - targets: ['am-1:9093', 'am-2:9093'] Experment on Docker12345678910111213141516171819202122232425262728293031version: '2'services: alertmanager_peer1: image: prom/alertmanager:latest volumes: - /etc/timezone:/etc/timezone - /etc/localtime:/etc/localtime - ./simple.yml:/etc/alertmanager/simple.yml command: [ '-config.file=/etc/alertmanager/simple.yml', '-mesh.peer=alertmanager_peer2:6783' ] ports: - '9093:9093' hostname: 'alertmanager_peer1' links: - alertmanager_peer2 alertmanager_peer2: image: prom/alertmanager:latest volumes: - /etc/timezone:/etc/timezone - /etc/localtime:/etc/localtime - ./simple.yml:/etc/alertmanager/simple.yml command: [ '-config.file=/etc/alertmanager/simple.yml', '-mesh.peer=alertmanager_peer1:6783' ] ports: - '9094:9093' hostname: 'alertmanager_peer2' 12345678alerting: alertmanagers: - scheme: http static_configs: - targets: [ \"10.200.3.98:9093\", \"10.200.3.98:9094\" ] Alert Stats1inactive --&gt; pending --&gt; firing 12345678910111213Connections:Address: 172.18.0.4:59634Info: none 02:42:ac:12:00:04(alertmanager_peer1)State: pendingAddress: 172.18.0.2:6783Info: none 02:42:ac:12:00:02(alertmanager_peer3)State: pendingAddress: 172.18.0.4:6783Info: Multiple connections to 02:42:ac:12:00:04(alertmanager_peer1) added to 02:42:ac:12:00:03(alertmanager_peer2), retry: 2018-01-31 16:55:58.292680256 +0800 CST m=+105335.286293642State: failed PromQL12345678910topk(10, count by (__name__)(&#123;__name__=~\".+\"&#125;))topk(10, count by (job)(&#123;__name__=~\".+\"&#125;))sum(sort_desc(sum_over_time(ALERTS&#123;alertstate=`firing`&#125;[24h]))) by (alertname)count(ALERTS&#123;alertstate=`firing`&#125;) by (alertname)sum(rate(container_cpu_user_seconds_total&#123;beta_kubernetes_io_os=\"linux\"&#125;[10m])) by (instance)topk(5, sum(rate(container_cpu_user_seconds_total&#123;&#125;[1h])) by (instance, pod_name)) Or query 123up&#123;instance=~\"192.168.156.30:9102|192.168.38.25:9102\"&#125;up&#123;job=\"mysql_exporter\"&#125; or up&#123;job=\"redis_exporter\"&#125; Prometheus Metric12345MustNewConstMetric(desc *Desc, valueType ValueType, value float64, labelValues ...string)NewDesc(fqName, help string, variableLabels []string, constLabels Labels)BuildFQName(namespace, subsystem, name string) e.g: 12345678910ch &lt;- prometheus.MustNewConstMetric( prometheus.NewDesc( prometheus.BuildFQName(namespace, mountsInfoSubsystem, \"state\"), \"Mounts State Info, via /proc/mounts (ro-Readonly, rw-ReadWrite)\", []string&#123;\"device\", \"mountpoint\", \"fstype\", \"mountstate\"&#125;, nil, ), prometheus.GaugeValue, value, minfo[\"device\"], minfo[\"mountpoint\"], minfo[\"fstype\"], minfo[\"mountstate\"],) Prometheus Federation12345678910111213141516- job_name: 'federate' scrape_interval: 15s honor_labels: true metrics_path: '/federate' params: 'match[]': - '&#123;job=\"prometheus\"&#125;' - '&#123;__name__=~\"job:.*\"&#125;' static_configs: - targets: - 'source-prometheus-1:9090' - 'source-prometheus-2:9090' - 'source-prometheus-3:9090' Hierarchical federation12345678910111213141516global: external_labels: datacenter: global # In a HA setup, this would be global1 or global2scrape_configs: - job_name: datacenter_federation honor_labels: true metrics_path: /federate params: match[]: - '&#123;__name__=~\"^job:.*\"&#125;' static_configs: - targets: - eu-west-1-prometheus:9090etc. sharding mode 123456789101112131415161718global: scrape_interval: 15s external_labels: monitor: 'prome-master'scrape_configs: - job_name: federate honor_labels: true metrics_path: /federate params: 'match[]': - '&#123;__name__=~\".+\"&#125;' static_configs: - targets: [ \"prome-salve-01:9090\", \"prome-slave-02:9090\", \"prome-slave-03:9090\" ] Refers Monitoring with Prometheus, Grafana &amp; Docker How to Setup Monitoring for Docker Containers using Prometheus PROMETHEUS CONFIGURATION http://codeblog.dotsandbrackets.com/highly-available-kafka-cluster-docker/ Writing a Jenkins exporter in Python Push Based Monitoring Service with Prometheus Prometheus Pushgateway KubeCon 2017 - Prometheus Takeaways Understanding and Extending Prometheus AlertManager Features Prometheus 2.0: New storage layer dramatically increases monitoring scalability for Kubernetes and other distributed systems Writing a Time Series Database from Scratch System Properties Comparison InfluxDB vs. Prometheus Solutions 360基于Prometheus的在线服务监控实践 Prometheus在Kubernetes下的监控实践 基于etcd+confd对监控prometheus的服务注册发现 收集golangruntime指标 New Found Netsil Netdata","tags":[{"name":"prometheus","slug":"prometheus","permalink":"http://keleir.github.io/tags/prometheus/"}]},{"title":"Consul Usage","date":"2017-01-27T08:48:32.000Z","path":"2017/01/27/Consul-Usage/","text":"Consul TCP/RPC 8300 Node Lan Gossip 8301 Client Wan Gossip 8302 Server Http 8500 API/UI DNS 8500 Dig Start Agent1consul agent -dev Members1234consul membersNode Address Status Type Build Protocol DC Segmenttest-1 127.0.0.1:8301 alive server 1.0.0 2 dc1 &lt;all&gt; 12345678910111213141516171819curl localhost:8500/v1/catalog/nodes[ &#123; \"CreateIndex\": 5, \"Meta\": &#123; \"consul-network-segment\": \"\" &#125;, \"Datacenter\": \"dc1\", \"ModifyIndex\": 6, \"Address\": \"127.0.0.1\", \"TaggedAddresses\": &#123; \"lan\": \"127.0.0.1\", \"wan\": \"127.0.0.1\" &#125;, \"Node\": \"bj-rc-devops-dkl-v-test-1.host.dataengine.com\", \"ID\": \"0e6c609d-c54b-c28b-95b1-827bff85ee64\" &#125;] Consul ClusterServer Mode123nohup consul agent -server -bootstrap-expect=1 \\ -data-dir=/opt/Consul/data -node=kallen-1 -bind=10.200.3.98 \\ -enable-script-checks=true -config-dir=/opt/Consul/etc/consul.d &gt; consul.log 2&gt;&amp;1 &amp; Agent Mode12nohup consul agent -data-dir=/opt/Consul/data -node=kallen-2 \\ -bind=10.200.3.100 -enable-script-checks=true -config-dir=/opt/Consul/etc/consul.d &gt; consul.log 2&gt;&amp;1 &amp; Start WebUI12nohup consul agent -ui -data-dir=/opt/Consul/data -node=kallen-2 \\ -bind=10.200.3.100 -enable-script-checks=true -config-dir=/opt/Consul/etc/consul.d &gt; consul.log 2&gt;&amp;1 &amp; 12nohup consul agent -ui -client=0.0.0.0 -data-dir=/opt/Consul/data -node=kallen-2 \\ -bind=10.200.3.100 -enable-script-checks=true -config-dir=/opt/Consul/etc/consul.d &gt; consul.log 2&gt;&amp;1 &amp; -client 0.0.0.0 Sets the address to bind for client access. This includes RPC, DNS,HTTP and HTTPS (if configured). Join Cluster123consul join 10.200.3.100 Successfully joined cluster by contacting 1 nodes. Leave Cluster123456consul leaveconsul membersNode Address Status Type Build Protocol DC Segmentkallen-1 10.200.3.98:8301 alive server 1.0.0 2 dc1 &lt;all&gt;kallen-2 10.200.3.100:8301 left client 1.0.0 2 dc1 &lt;default&gt; Service Register1234567891011PUT http://10.200.3.100:8500/v1/agent/service/register&#123; \"address\": \"10.200.3.98\", \"id\": \"httpd_exporter_1\", \"name\": \"httpd_exporter_1\", \"port\": 9413, \"tags\": [ \"kallen\" ]&#125; Check12345678\"check\": &#123; \"name\": \"mysql_exporter_check\", \"http\": \"http://10.200.3.98:33109/metrics\", \"tls_skip_verify\": false, \"method\": \"GET\", \"interval\": \"60s\", \"timeout\": \"1s\" &#125; Service Deregister12345PUT http://10.200.3.100:8500/v1/agent/service/deregister/node_exporter_1&#123; \"ID\": \"node_exporter_1\"&#125; 基于ZooKeeper、Etcd等分布式键值对存储服务来建立服务发现系统在现在看起来也不是一种很好的方案，一方面是因为它们只能提供基本的数据存储功能，还需要在外围做大量的开发才能形成完整的服务发现方案。另一方面是因为它们都是强一致性系统，在集群发生分区时会优先保证一致性、放弃可用性，而服务发现方案更注重可用性，为了保证可用性可以选择最终一致性 Refers 服务发现系统consul-HTTP API Raft算法演示 在线支付公司Stripe的服务发现架构设计过程分享 Consul 简介和快速入门","tags":[{"name":"consul","slug":"consul","permalink":"http://keleir.github.io/tags/consul/"}]},{"title":"《追风筝的人》读书札记","date":"2016-05-16T06:32:06.000Z","path":"2016/05/16/the-kite-runner-reading-notes/","text":"真正的男人不看诗——真主也禁止他们创作呢。真正的男人——真正的男孩——应该像爸爸小时候那样踢足球去，那才是值得付出热情的玩意儿。 十二岁以前，我大部分时间都在跟哈桑玩耍。有时候回想起来，我的整个童年，似乎就是和哈桑一起度过的某个懒洋洋的悠长夏日，我们在爸爸院子里那些交错的树木中彼此追逐，玩捉迷藏，玩警察与强盗，玩牛仔和印第安人，折磨昆虫——我们拔掉蜜蜂的尖刺，在那可怜的东西身上系根绳子，每当它想展翅飞走，就把它拉回来，这带给我们无与伦比的快乐。 那是个悲伤的小故事，讲的是有个男人发现了一个魔法杯，得知如果他对着杯子哭泣，掉进杯里的眼泪会变成珍珠。可尽管一贫如洗，他却是个快乐的家伙，罕得流泪。于是他想方设法，让自己悲伤，以便那些眼泪会变成他的财富。珍珠越积越多，他越来越贪婪。小说的结尾是，那男人坐在一座珠宝山上，手里提着刀，怀中抱着他深爱着的妻子死于非命的尸体，无助地将眼泪滴进魔法杯。 我朝西望去，觉得真是奇妙，在峰峦那边的某处，喀布尔依然存在。它真的存在，不只是久远的记忆，不只是《旧金山纪事报》第十五版上某篇美联社报道的标题。西方的山脉那边某个地方有座沉睡的城市，我的兔唇弟弟和我曾在那里追过风筝。那边某个地方，我梦中那个蒙着眼的男人死于非命。曾经，在山那边，我作过一个抉择。而如今，时隔四分之一个世纪，正是那个抉择让我重返这片土地。 它只是一个微笑，没有别的了。它没有让所有事情恢复正常。它没有让任何事情恢复正常。只是一个微笑，一件小小的事情，像是树林中的一片叶子，在惊鸟的飞起中晃动着。但我会迎接它，张开双臂。因为每逢春天到来，它总是每次融化一片雪花；而也许我刚刚看到的，正是第一片雪花的融化。","tags":[{"name":"reading","slug":"reading","permalink":"http://keleir.github.io/tags/reading/"},{"name":"books","slug":"books","permalink":"http://keleir.github.io/tags/books/"}]},{"title":"Flask基础简介","date":"2016-04-07T08:51:01.000Z","path":"2016/04/07/flask-learning-notes/","text":"1.Flask Intor12345678910from flask import Flaskapp = Flask(__name__)@app.route('/')def hello_world(): return 'Hello World!'if __name__ == '__main__': app.run() 2.Redirect12345678910from flask import abort, redirect, url_for@app.route('/')def index(): return redirect(url_for('login')) @app.route('/login')def login(): abort(401) this_is_never_executed() 3.Session123456789101112131415161718192021222324252627282930from flask import Flask, session, redirect, url_for, escape, requestapp = Flask(__name__)@app.route('/')def index(): if'username'in session: return 'Logged in as %s' % escape(session['username']) return 'You are not logged in' @app.route('/login', methods=['GET', 'POST'])def login(): if request.method == 'POST': session['username'] = request.form['username'] return redirect(url_for('index')) return ''' &lt;form action=\"\" method=\"post\"&gt; &lt;p&gt;&lt;input type=text name=username&gt; &lt;p&gt;&lt;input type=submit value=Login&gt; &lt;/form&gt; ''' @app.route('/logout')def logout(): # 如果用户名存在，则从会话中移除该用户名 session.pop('username', None) return redirect(url_for('index'))# 设置密钥，保证会话安全app.secret_key = '0Zr98j/3yX R~XHH!jmN]LWX/,?R' 4.Router(1) route装饰器可以使用Flask应用实例的route装饰器将一个URL规则绑定到 一个视图函数上。 例如，下面的示例将URL规则/test绑定到视图函数test()上： 123@app.route('/test')def test(): return'this is response' 在Flask中，转换器/converter用来对从URL中提取的变量进行预处理，这个过程 发生在调用视图函数之前。 Flask预置了四种转换器： string - 匹配不包含/的字符串，这是默认的转换器 path - 匹配包含/的字符串 int - 只有当URL中的变量是整型值时才匹配，并将变量转换为整型 float - 只有当URL中的变量是浮点值时才匹配，并将变量转换为浮点型 (2) add_url_rule()另一种等价的写法是使用Flask应用实例的add_url_rule()方法。下面的示例注册了一个与前例相同的路由： 1234def test(): return 'this is response' app.add_url_rule('/test',view_func=test) 为路由指定请求方法： 123456@app.route('/user',methods=['POST','GET'])def v_users(): if request.method == 'GET': return ... # 返回用户列表 if request.method == 'POST' return ... #创建新用户 Litte Demo:1234567891011121314151617181920212223# -*- coding:utf-8-*-from flask import Flaskapp = Flask(__name__)@app.route('/')def v_index(): return ''' &lt;form action=\"/auth\" method=\"POST\"&gt; &lt;input type=\"text\" name=\"uid\"&gt; &lt;input type=\"password\" name=\"pwd\"&gt; &lt;input type=\"submit\" value=\"submit\"&gt; &lt;/form&gt; ''' @app.route('/auth',methods=['GET', 'POST'])def v_auth(): if request.method == 'GET': return 'GET REQ' if request.method == 'POST': return 'POST REQ' app.run(host='0.0.0.0',port=80) (3) 访问点/endpoint在 Flask框架中，请求任务的分发并不是直接从用户请求的URL一步定位到视图函数， 两者之间隔着一个访问点/endpoint。 在Flask内部使用两张表维护路由： url_map ：维护URL规则和endpoint的映射 view_functions ：维护endpoint和视图函数的映射 以用户访问URL/home为例，Flask将首先利用url_map找到所请求URL对应的 endpoint，即访问点home，然后再利用view_functions表查找home这个访问点 对应的视图函数，最终匹配到函数home()： 123@app.route('/home')def home(): pass (4)静态目录路由当创建应用实例时，Flask将自动添加一条静态目录路由，其访问点 始终被设置为static，URL规则默认被设置为/static，本地路径默认被 设置为应用文件夹下的static子文件夹; 改变默认的本地路径：可以在创建应用对象时使用关键字参数 static_folder 改变 默认的静态文件夹。 例如，你的静态文件都存放在应用下的assets目录下， 那么可以按如下的方式创建应用对象： 1app = Flask(__name__, static_folder='assets') 也可以使用一个绝对路径： 1app =Flask(__name__,static_folder='/var/www/static') 改变默认的本地路径并不会对路由表产生影响。 改变默认的URL规则 ：如果不喜欢静态目录URL/static，也可以在创建应用 对象时使用关键字参数 static_url_path 换一个别的名字。 下面的示例中，将应用下的assets文件夹注册为静态目录/assets： 1app =Flask(__name__,static_folder='assets',static_url_path='/assets') (5) url_for()添加URL变量：如果指定访问点对应的视图函数接收参数，那么关键字参数将生成对应的参数URL。 下面的示例将生成 /contact/Julia?format=html： 123456789@app.route('/')def v_index(): print url_for('v_contact',name='Julia',format='html') return ''@app.route('/contact/&lt;name&gt;')def v_contact(name): pass&lt;/name&gt; 添加锚点 ：使用_anchor关键字可以为生成的URL添加锚点。 下面的示例将生成URL /contact#part2 1234567@app.route('/')def v_index(): print url_for('v_contacts',_anchor='part2') @app.route('/contact')def v_contacts(): pass 外部URL：默认情况下，url_for()生成站内URL，可以设置关键字参数 _external 为True，生成包含站点地址的外部URL。 下面的示例将生成URL http:///contacts: 1234567@app.route('/')def v_index(): print url_for('v_contacts', _external=True) @app.route('/contact')def v_contacts(): pass 5.Request &amp; request form - 记录请求中的表单数据。类型：MultiDict args - 记录请求中的查询参数。类型：MultiDict cookies - 记录请求中的cookie。类型：Dict headers - 记录请求中的报文头。类型：EnvironHeaders method - 记录请求使用的HTTP方法：GET/POST/PUT….。类型：string environ - 记录WSGI服务器转发的环境变量。类型：Dict url - 记录请求的URL地址。类型：string 6.Global Varible(1) g.user在login view方法中我们通过检查 g.user 来判断一个用户是否登录了,为了实现这个我们将使用Flask提供的 before_request 事件。 任何一个被before_request装饰器装饰的方法将会在每次request请求被收到时提前与view方法执行。所以在这儿来设置我们的g.user变量(app/views.py)： 123@app.before_requestdef before_request(): g.user = current_user 这就是它要做的一切，current_user 全局变量是被 Flask-Login 设定的，所以我们只需要把它拷贝到更容易被访问的 g 变量就OK了。 这样，所有的请求都能访问这个登录的用户，甚至于内部的模板。 References 欢迎进入Flask大型教程项目 Flask学习之用户登录","tags":[{"name":"flask","slug":"flask","permalink":"http://keleir.github.io/tags/flask/"},{"name":"route","slug":"route","permalink":"http://keleir.github.io/tags/route/"}]},{"title":"前端知识点汇总","date":"2016-03-04T02:59:01.000Z","path":"2016/03/04/fronted-useful-tips/","text":"1.Bootstrap Modal Draggable12345678$(document).on(\"show.bs.modal\", \".modal\", function()&#123; $(this).draggable(&#123; // handle: \".modal-header\" // 只能点击头部拖动 &#125;); $(this).css(\"overflow\", \"hidden\"); // 防止出现滚动条，出现的话，你会把滚动条一起拖着走的&#125;); show.bs.modal: 在调用 show 方法后触发。1$(\"#identifier\").on('show.bs.modal', function()&#123;//do sth. &#125;); show.bs.modal 当模态框对用户可见时触发（将等待 CSS 过渡效果完成）。1$(\"#identifier\").on('shown.bs.modal', function()&#123;//do sth. &#125;); hide.bs.modal 当调用 hide 方法时触发。1$(\"#identifier\").on('hide.bs.modal', function()&#123;//do sth. &#125;); hidden.bs.modal 当模态框完全对用户隐藏时触发。1$(\"#identifier\").on('hidden.bs.modal', function()&#123;//do sth. &#125;) 需加载jquery-ui.min.js12345678$(document).ready(function()&#123; //为模态对话框添加拖拽 $(\"#modalDialog\").draggable(); //禁止模态对话框的半透明背景滚动 $(\"#myModal\").css(\"overflow\", \"hidden\");&#125;) 2.Location Object Location 对象属性 属性 描述 hash 设置或返回从井号 (#) 开始的 URL（锚）。 host 设置或返回主机名和当前 URL 的端口号。 hostname 设置或返回当前 URL 的主机名。 href 设置或返回完整的 URL。 pathname 设置或返回当前 URL 的路径部分。 port 设置或返回当前 URL 的端口号。 protocol 设置或返回当前 URL 的协议。 search 设置或返回从问号 (?) 开始的 URL（查询部分） 12var searchStr = location.search;location.href = location.pathname + qry; onclick=&quot;javascript:location.href=&apos;/trouble/list&apos;&quot; 3.Select Object (1) 删除全部option： $(&quot;#select&quot;).empty(); (2) 添加一项option： 1$(\"#select_id\").append(\"&lt;option value='value'&gt;text&lt;/option&gt;\"); (3) 创建option对象：opt = new Option(name, value); 123456789101112131415// 产品线与集群二级联动下拉菜单$(\"#proline_select\").change(function() &#123; var cluster_list = $(\"#proline_select\").find(\"option:selected\").attr('tags').split(','); var cluster_select = $(\"#cluster_select\") cluster_select.empty() for(var i=0; i&lt;cluster_list.length; i++) &#123; opt = new Option(cluster_list[i], cluster_list[i]); cluster_select.append(opt); &#125; if ($(\"#proline_select\").val() == 0 || cluster_list == \"\") &#123; cluster_select.empty() var opt = new Option('集群名称', 0); cluster_select.append(opt); &#125;&#125;); (4) option选中与回显：12345678&lt;select class=\"selectpicker form-control\" name=\"mikey\"&gt; &lt;option value=\"\"&gt;请选择监控指标&lt;/option&gt; &#123;% for key in mikey_list %&#125; &lt;option value=\"&#123;&#123; key['mikey'] &#125;&#125;\" &#123;% if mikey == key %&#125; selected = \"selected\" &#123;% endif %&#125;&gt; &#123;&#123; key['mikey'] &#125;&#125;&lt;/option&gt; &#123;% endfor %&#125;&lt;/select&gt; 4.Checkbox Object123&lt;th class=\"text-center\"&gt;&lt;input type=\"checkbox\" id=\"all_alive\" onclick=\"checkAll('all_alive', 'checked')\"&gt;&lt;/th&gt; 12345678910111213141516// Checkbox Function//此函数用于checkbox的全选和反选var checked=false;function check_all(form) &#123; var checkboxes = document.getElementById(form); if (checked == false) &#123; checked = true &#125; else &#123; checked = false &#125; for (var i = 0; i &lt; checkboxes.elements.length; i++) &#123; if (checkboxes.elements[i].type == \"checkbox\") &#123; checkboxes.elements[i].checked = checked; &#125; &#125;&#125; 123456789101112131415function checkAll(id, name)&#123; var checklist = document.getElementsByName(name); if(document.getElementById(id).checked) &#123; for(var i=0;i&lt;checklist.length;i++) &#123; checklist[i].checked = 1; //checklist[i].classList.add(\"info\"); checklist[i].parentNode.parentNode.classList.add(\"info\"); &#125; &#125; else &#123; for(var j=0;j&lt;checklist.length;j++) &#123; checklist[j].checked = 0; checklist[j].parentNode.parentNode.classList.remove(\"info\"); &#125; &#125;&#125; 5.JQuery Cookie(1) jquery-cookie导入1&lt;script type=\"text/javascript\" src=\"js/jquery.cookie.js\"&gt;&lt;/script&gt; (2) 新添加一个会话cookie1$.cookie('the_cookie', 'the_value'); 当没有指明 cookie有效时间时，所创建的cookie有效期默认到用户关闭浏览器为止，所以被称为”会话cookie(session cookie)”. (3) 创建一个cookie并设置有效时间为7天1$.cookie('the_cookie', 'the_value', &#123; expires: 7 &#125;); 当指明了cookie有效时间时，所创建的cookie被称为”持久cookie(persistent cookie)”. (4) 创建一个cookie并设置有效路径1$.cookie('the_cookie', 'the_value', &#123; expires: 7, path: '/' &#125;); 在默认情况下，只有设置cookie的网页才能读取该cookie； 如果想让一个页面读取另一个页面设置的cookie，必须设置cookie的路径； cookie的路径用于设置能够读取cookie的顶级目录； 将这个路径设置为网站的根目录，可以让所有网页都能互相读取cookie； 一般不要这样设置，防止出现冲突； (5) 读取cookie12$.cookie('the_cookie'); // cookie存在 =&gt; 'the_value' $.cookie('not_existing'); // cookie不存在 =&gt; null (6) 删除cookie 通过传递null作为cookie的值即可： 1$.cookie('the_cookie', null); 如果想删除一个带有效路径的cookie，如下： 1$.cookie('cookieName', null, &#123;path:'/'&#125;); 注： jquery-cookie.js的版本要用最新的v1.4.1, v1.3.x会报 URIError: URI malformed； e.g (1)：12345678910111213&lt;script type=\"text/javascript\" &gt; var tabcookievalue = $.cookie(\"mytab\"); if (tabcookievalue != \"\") &#123; nTabs( $(\"#myTab li\").eq(tabcookievalue)[0], tabcookievalue ); &#125; $(\"#myTab li\").click(function () &#123; $.cookie(\"mytab\", $(this).index()); &#125;);&lt;/script&gt; e.g (2)：12345678910111213141516$(document).ready(function() &#123; // Store cookie when click tabs $(\"#equip_ul li\").click(function() &#123; $.cookie(\"equip_tab\", $(this).index(), &#123; expires: 7, raw: true &#125;); &#125;); var tab_index = $.cookie(\"equip_tab\"); if (tab_index != \"\") &#123; $(\"#equip_ul li\").removeClass(\"active\"); $(\"#equip_pane .tab-pane\").removeClass(\"active\"); var tab_li = $(\"#equip_ul li\").eq(tab_index); var panel = $(tab_li).children('a').attr('href'); $(tab_li).addClass(\"active\"); $(panel).addClass(\"active\"); &#125;&#125; 6.Tables(1) word-wrap12345&lt;table style=\"table-layout: fixed;\"&gt; &lt;tr&gt; &lt;td style=\"word-wrap: break-word;\"&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt; (2) text-align-last123&lt;td style=\"text-align-last: center;\"&gt;&lt;/td&gt;&lt;td style=\"text-align-last: center;\"&gt;&lt;/td&gt;&lt;td style=\"text-align-last: center;\"&gt;&lt;/td&gt; [REFERENCE] cookie读写插件jquery.cookie.js http://www.layui.com/ Beautiful Flat Icons","tags":[{"name":"jquery","slug":"jquery","permalink":"http://keleir.github.io/tags/jquery/"},{"name":"html","slug":"html","permalink":"http://keleir.github.io/tags/html/"}]},{"title":"Django基础简介","date":"2016-02-28T10:50:25.000Z","path":"2016/02/28/django-learning-notes/","text":"1.Django Intor 官方网站：https://www.djangoproject.com/开源地址：https://github.com/django/django 2.Django Install(1) PIP安装12sudo apt-get install python-pipsudo pip install Django (2)源码安装123456789101112131415161718/usr/local/share/Django/Django-1.8.3.tar.gzDjango-1.8.3├── AUTHORS├── build├── dist├── django├── Django.egg-info├── docs├── extras├── INSTALL├── LICENSE├── MANIFEST.in├── PKG-INFO├── README.rst├── scripts├── setup.cfg├── setup.py└── tests 1sudo python setup.py install 3.Django Project(1)创建项目123456789root@kallen:Django# django-admin startproject MyProjroot@kallen:Django# tree MyProj/MyProj/├── manage.py└── MyProj ├── __init__.py ├── settings.py ├── urls.py └── wsgi.py init.py：Django项目是Python包，这个文件是用来告诉Python这个文件夹当做一个包。在Python术语中，包是一组模块的集合，主要用来把相似的文件分组，防止出现命名冲突。 manage.py：这个脚步用来管理你的项目，你可以把它看做是你项目的的django admin.py版本，其实，manage.py和django-admin.py是共用相同的后台代码。 settings.py： 这是Django项目的主要配置文件，在这个文件里面，你可以具体说明很多选项，包括数据库设置、网页语言、需要turn on的Django功能。 urls.py：这是另外一个配置文件。你可以把它看做是介于URLS和用来处理它们的Python方法之间的匹配; (http://www.cnblogs.com/bluescorpio/archive/2009/11/28/1612805.html) (2)创建应用12345678910111213root@kallen:Django# python manage.py startapp jobs└── MyProj ├── jobs │ ├── admin.py | |—— url.py │ ├── __init__.py │ ├── migrations │ │ └── __init__.py │ ├── models.py │ ├── tests.py │ └── views.py ├── manage.py └── MyProj (3)配置数据库12345678910DATABASES = &#123; 'default': &#123; 'ENGINE': 'django.db.backends.mysql', 'NAME': 'myapp', 'USER': 'root', 'PASSWORD': 'root', 'HOST': '127.0.0.1', 'PORT': '3306' &#125;&#125; (4)创建实体类12345678910from django.db import modelsclass Job(models.Model): pub_date = models.DateField() job_title = models.CharField(max_length=50) job_description = models.TextField() location = models.ForeignKey(Location) def__str__(self): return\"%s (%s)\" % (self.job_title, self.location) (5)查看数据库模式123456789101112131415161718root@kallen# python manage.py sql jobsBEGIN;CREATE TABLE `jobs_location` ( `id` integer AUTO_INCREMENT NOT NULL PRIMARY KEY, `city` varchar(50)NOT NULL, `state` varchar(50), `country` varchar(50)NOT NULL);CREATE TABLE `jobs_job` ( `id` integer AUTO_INCREMENT NOT NULL PRIMARY KEY, `pub_date` date NOT NULL, `job_title` varchar(50)NOT NULL, `job_description` longtext NOT NULL, `location_id` integerNOT NULL);ALTER TABLE `jobs_job` ADD CONSTRAINT `location_id_refs_id_35f2feb6` FOREIGN KEY (`location_id`) REFERENCES `jobs_location` (`id`);COMMIT; 1234$ python manage.py sql jobsCommandError: App 'jobs' has migrations. Only the sqlmigrate and sqlflush commandscan be used when an app has migrations. 【解决办法】删除jobs下的migrations就可以了； (6)检查数据库模式12345678910111213141516171819202122root@kallen:MyProj# python manage.py validate/usr/local/lib/python2.7/dist-packages/Django-1.8.3-py2.7.egg/django/core/management/commands/validate.py:15: RemovedInDjango19Warning:\"validate\" has been deprecated in favor of\"check\".RemovedInDjango19Warning)System check identified no issues (0 silenced).root@kallen:/home/kallen/Python/Django/MyProj#python manage.py makemigrationsMigrations for 'jobs':0001_initial.py:- Create model Job- Create model Location- Add field location to jobroot@kallen:/home/kallen/Python/Django/MyProj#python manage.py migrateOperations to perform: Synchronize unmigrated apps: staticfiles, messages Apply all migrations: admin, contenttypes, jobs, auth, sessionsSynchronizing apps without migrations: Creating tables... Running deferred SQL... Installing custom SQL...Running migrations: Rendering model states... DONE Applying jobs.0001_initial... OK (7)启动测试服务器123456789root@kallen:/MyProj# python manage.py runserverPerforming system checks...System check identified no issues (0 silenced).You have unapplied migrations; your app may not work properly until they are applied.Run 'python manage.py migrate' to apply them.August 14,2015-05:55:23Django version 1.8.3, using settings 'MyProj.settings'Starting development server at http://127.0.0.1:8000/Quit the server with CONTROL-C. (8)后台管理12python manage.py createsuperuser # 创建管理帐号python manage.py syncdb (9)注册模型123456789from django.contrib issmport admin# Register your models here.# Register my models of job for mapping # utility class Location &amp; Job.# Kallen Ding, Agu 17 2015from .models import Location, Job admin.site.register(Location)admin.site.register(Job) 4.Django QuerySet(1)条件查询1234567891011121314151617181920条件选取querySet的时候，filter表示=，exclude表示!=。 querySet.distinct() 去重复 __exact 精确等于 like 'aaa'__iexact 精确等于 忽略大小写 ilike 'aaa'__contains 包含 like '%aaa%'__icontains 包含 忽略大小写 ilike '%aaa%'，但是对于sqlite来说，contains的作用效果等同于icontains。 __gt 大于 __gte 大于等于 __lt 小于 __lte 小于等于 __in 存在于一个list范围内 __startswith 以...开头 __istartswith 以...开头 忽略大小写 __endswith 以...结尾 __iendswith 以...结尾，忽略大小写 __range 在...范围内 __year 日期字段的年份 __month 日期字段的月份 __day 日期字段的日 __isnull=True/False (2)查询集排序12Log.objects.filter(user=user.username).order_by('-start_time')Log.objects.filter(user=user.username).order_by('-id') 5.Django Form在html页面，代码超简单，这点django做的不错 1234567891011121314&lt;form id=\"your-profile\" action=\"/contact\" method=\"post\"&gt;&lt;table class=\"form-table\"&gt;&lt;!--&#123;&#123; form.as_ul &#125;&#125;--&gt; # 这是第一种写法，在&lt;ul&gt; 显示表单&lt;!-- &#123;&#123; form.as_p &#125;&#125;--&gt; # 这是第二种写法，在&lt;p&gt; 显示表单&lt;!--&#123;&#123; form.as_table &#125;&#125;--&gt; # 这是第三种写法，在&lt;table&gt;显示表单&#123;% for field in form %&#125; # 这是第四种写法，以循环形式显示表单&#123;&#123; field.label_tag &#125;&#125;:&#123;&#123; field &#125;&#125;&#123;&#123; field.errors &#125;&#125;&#123;% endfor %&#125;&lt;/table&gt;&lt;p class=\"submit\"&gt;&lt;input type=\"submit\" name=\"submit\" id=\"submit\"class=\"button-primary\" value=\"注册信息\"/&gt;&lt;/p&gt;&lt;/form&gt; 6.Django Request(1) request.META一个Python字典，包含了所有本次HTTP请求的Header信息，比如用户IP地址和用户Agent（通常是 浏览器的名称 和 版本号）。 注意，Header信息的完整列表取决于用户所发送的Header信息和服务器端设置的Header信息。 这个字典中几个常见的键值有： HTTP_REFERRER进站前链接网页，如果有的话; HTTP_USER_AGENT用户浏览器的user-agent字符串，如果有的话。例如： “Mozilla/5.0 (X11; U; Linux i686; fr-FR; rv:1.8.1.17) Gecko/20080829 Firefox/2.0.0.17”. REMOTE_ADDR客户端IP，如：”12.345.67.89” 。(如果申请是经过代理服务器的话，那么它可能是以逗号分割的多个IP地址，如：”12.345.67.89,23.456.78.90”) [注意] 因为 request.META 是一个普通的Python字典，因此当你试图访问一个不存在的键时，会触发一个 KeyError异常 （HTTP header信息是由用户的浏览器所提交的、不应该给予信任的”额外”数据，因此你总是应该好好设计你的应用以便当一个特定的Header数据不存在时，给出一个优雅的回应） 你应该用 try/except 语句，或者用Python字典的get() 方法来处理这些“可能不存在的键”： 1234# BAD!def ua_display_bad(request): ua = request.META['HTTP_USER_AGENT']# Might raise KeyError! return HttpResponse(\"Your browser is%s\" % ua) 1234567# GOOD (VERSION 1)def ua_display_good1(request): try: ua = request.META['HTTP_USER_AGENT'] except KeyError: ua ='unknown' return HttpResponse(\"Your browser is%s\" % ua) 1234# GOOD (VERSION 2)def ua_display_good2(request): ua = request.META.get('HTTP_USER_AGENT','unknown') return HttpResponse(\"Your browser is%s\" % ua) 7.Static &amp; Media12345678from django.conf import settingsif settings.DEBUG: urlpatterns += patterns('', url(r'^upload/(?P&lt;path&gt;.*)$', 'django.views.static.serve', &#123;'document_root':settings.MEDIA_ROOT&#125;), ) 8.Migrations在1.6之前, Django只支持添加新的model到数据库, 而无法编辑或修改已经存在的model. Django 1.7 为我们带来了三个新命令: migrate: 用于执行迁移动作 makemigrations: 基于当前的model创建新的迁移策略文件 sqlmigrate: 显示迁移的SQL语句 值得注意的是, migration是基于App的, 因此, 我们可以针对某些app不启用migration功能. migrations 的使用非常简单： 修改model, 比如增加field, 然后运行 1python manager.py makemigrations 你的model会被扫描, 然后与之前的版本作比较, 在app的migrations目录下生成本次迁移文件. 我们建议查看一下该迁移文件, 确保没有问题. 然后运行: 1python manager.py migrate migrate 命令会进行比较, 并应用该迁移. 9.Many to Many(1) 添加对象123a = Author.objects.get(id=1) b = Book.objects.get(id=50) b.authors.add(a) 12b.authors.count()b.authors.all() (2) 删除对象12345a = Author.objects.get(id=1)b = Book.objects.get(id=50)b.authors.remove(a) 或者 b.authors.filter(id=1).delete() 12# 删除全部b.authors.clear() 10.Django FAQ(1) 导入MySQL错误1django.core.exceptions.ImproperlyConfigured: Error loading MySQLdb module 【解决办法】安装mysql-python模块 安装步骤：12345sudo apt-get install python-setuptoolssudo apt-get install libmysqld-devsudo apt-get install libmysqlclient-dev sudo apt-get install python-devsudo easy_install mysql-python 测试下： 在python交互式窗口，import MySQLdb 试试，不报错的话，就证明安装好了。 (2) 导入model对象出错123456&gt;&gt;&gt;from jobs.models import Jobdjango.core.exceptions.ImproperlyConfigured: Requested setting DEFAULT_INDEX_TABLESPACE, but settings are not configured. You must either define the environment variable DJANGO_SETTINGS_MODULE or call settings.configure() before accessing settings. 【解决办法】12&gt;&gt;&gt;from django.conf import settings &gt;&gt;&gt; settings.configure() (3) CSRF Verification Failed123456789101112Forbidden (403)CSRF verification failed. Request aborted.HelpReason given for failure: CSRF token missing or incorrect.In general, this can occur when there is a genuine Cross Site Request Forgery, or when Django's CSRF mechanism has not been used correctly. For POST forms, you need to ensure:Your browser is accepting cookies.The view function passes a request to the template's render method.In the template, there is a `% csrf_token %` template tag inside each POST form that targets an internal URL.If you are not using CsrfViewMiddleware, then you must use csrf_protect on any views that use the csrf_token template tag, as well as those that accept the POST data.You're seeing the help section of this page because you have DEBUG =Truein your Django settings file. Change that to False, and only the initial error message will be displayed.You can customize this page using the CSRF_FAILURE_VIEW setting. 【解决办法】 第一种：在表单里加上 % csrf_token % 就行了。 第二种：在Settings里的MIDDLEWARE_CLASSES增加配置：12'django.middleware.csrf.CsrfViewMiddleware','django.middleware.csrf.CsrfResponseMiddleware', 方法二不可行： 12ImportError: Module \"django.middleware.csrf\" does not define a\"CsrfResponseMiddleware\" attribute/class 这种方式违反了django的初衷，正确的解决方案有两个： a.引入RequestContext：1234567891011from django.shortcuts import render_to_response, get_object_or_404,from django.template import RequestContext defedit(request,id):publisher =get_object_or_404(Publisher,id=id)if request.method =='POST':appForm =PublisherForm(request.POST, instance = publisher)if appForm.is_valid():publisher = appForm.save();publisher.save()returnHttpResponseRedirect(reverse(\"index\"))returnrender_to_response('books/edit.html', &#123;'form':PublisherForm(instance = publisher)&#125;, context_instance=RequestContext(request)) b.使用render方式渲染页面：12345from django.shortcuts import render_to_response, get_object_or_404, render defedit(request,id):同上 #return render_to_response('books/edit.html', &#123;'form': PublisherForm(instance = publisher)&#125;, context_instance=RequestContext(request)) returnrender(request,'books/edit.html', &#123;'form':PublisherForm(instance = publisher)&#125;) (4) Exception123456Exception happened during processing of request from ('127.0.0.1', 59311)Traceback (most recent call last): File \"/usr/lib/python2.7/SocketServer.py\", line 593, in process_request_threadException happened during processing of request from ('127.0.0.1', 59312)Traceback (most recent call last): File \"/usr/lib/python2.7/SocketServer.py\", line 593, in process_request_thread (5) IPAddressField1234arigue.Server.ipaddr: (fields.W900) IPAddressField has been deprecated.Support forit(except in historical migrations) will be removed in Django 1.9. HINT: Use GenericIPAddressField instead. 推荐使用 GenericIPAddressField() (6) Forbidden12345CSRF verification failed. Request aborted.HelpReason given for failure: CSRF token missing or incorrect. In general, this can occur when there is a genuine Cross Site Request Forgery, or when Django’s CSRF mechanism has not been used correctly. For POST forms, you need to ensure:Your browser is accepting cookies.The view function passes a request to the template’s render method.In the template, there is a % csrf_token % template tag inside each POST form that targets an internal URL.If you are not using CsrfViewMiddleware, then you must use csrf_protect on any views that use the csrf_token template tag, as well as those that accept the POST data.You’re seeing the help section of this page because you have DEBUG = True in your Django settings file. Change that to False, and only the initial error message will be displayed.You can customize this page using the CSRF_FAILURE_VIEW setting. (7) AppRegistryNotReady1django.core.exceptions.AppRegistryNotReady: Models aren't loaded yet. 【参考文章】 stackoverflow.com/questions/6315960","tags":[{"name":"django","slug":"django","permalink":"http://keleir.github.io/tags/django/"}]},{"title":"Memcache简易说明","date":"2016-01-14T15:17:01.000Z","path":"2016/01/14/memcached-brief-usage/","text":"1.安装memcached12yum install memcachedmemcached -h 2.启动memcached1memcached -d -m 100 -c 1000 -u root -p 33060 参数说明：12345678910111213-d 启动一个守护进程-m 分配给Memcache使用的内存数量，单位是MB，默认为64M-u 运行Memcache的用户(only when run as root)-l 监听的服务器IP地址-p Memcache监听的端口,默认为11211，最好是1024以上的端口-c 最大运行的并发连接数，默认是1024，按照服务器的负载量来设定-P 设置保存Memcache的pid文件 3.查看memcached状态(1) telnet ip port ==&gt; stats12345678910111213141516171819202122232425262728293031323334353637383940414243# telnet 127.0.0.1 33060Trying 127.0.0.1...Connected to 127.0.0.1.Escape character is '^]'.statsSTAT pid 7483STAT uptime 62616STAT time 1484028645STAT version 1.4.4STAT pointer_size 64STAT rusage_user 0.913861STAT rusage_system 0.691894STAT curr_connections 12STAT total_connections 16STAT connection_structures 13STAT cmd_get 15STAT cmd_set 5STAT cmd_flush 0STAT get_hits 9STAT get_misses 6STAT delete_misses 0STAT delete_hits 0STAT incr_misses 0STAT incr_hits 0STAT decr_misses 0STAT decr_hits 0STAT cas_misses 0STAT cas_hits 0STAT cas_badval 0STAT auth_cmds 0STAT auth_errors 0STAT bytes_read 5657STAT bytes_written 21447STAT limit_maxbytes 104857600STAT accepting_conns 1STAT listen_disabled_num 0STAT threads 4STAT conn_yields 0STAT bytes 5225STAT curr_items 3STAT total_items 5STAT evictions 0END (2) 模拟top命令1watch \"printf 'stats\\r\\n' | nc 127.0.0.1 33060\" 1watch \"echo stats | nc 127.0.0.1 33060\" 4.Python-memcached API12345678910import memcachemc = memcache.Client(['127.0.0.1:33060'], debug=0)if __name__ == '__main__': mc.set('name', 'kallen') mc.set('mail', 'kallen@mail.com') name = mc.get('name') mail = mc.get('mail') print name, mail 主要方法如下： @set(key, val, time=0, min_compress_len=0) 无条件键值对的设置，其中的time用于设置超时，单位是秒 min_compress_len则用于设置zlib压缩 @set_multi(mapping, time=0, key_prefix=&#39;&#39;, min_compress_len=0) 设置多个键值对，key_prefix是key的前缀，完整的键名是key_prefix+key, 使用方法如下： 123mc.set_multi(&#123;'k1' : 1, 'k2' : 2&#125;, key_prefix='pfx_') mc.get_multi(['k1', 'k2', 'nonexist'], key_prefix='pfx_')&#123;'k1' : 1, 'k2' : 2&#125; @add(key, val, time=0, min_compress_len=0) 添加一个键值对，内部调用_set()方法 @replace(key, val, time=0, min_compress_len=0) 替换value，内部调用_set()方法 @get(key) 根据key去获取value，出错返回None @get_multi(keys, key_prefix=&#39;&#39;) 获取多个key的值，返回的是字典, keys为key的列表 @delete(key, time=0) 删除某个key, time的单位为秒; 用于确保在特定时间内的set和update操作会失败。 如果返回非0则代表成功 @incr(key, delta=1) 自增变量加上delta，默认加1，使用如下 123mc.set(\"counter\", \"20\") mc.incr(\"counter\")21 @decr(key,delta=1) 自减变量减去delta，默认减1 123456789101112131415161718# memcached 初始化mc = memcache.Client(['服务器A IP:11211'], debug=0)class test: def GET(self): sql = \"select * from table\" m = hashlib.md5(sql) key = m.hexdigest() retval = [] if mc.get(key): retval = mc.get(key) else: retval = db.query(sql).list() mc.set(key, retval ) # 断开连接 mc.disconnect_all() [REFERENCE] Memcache Examples Linux下安装memcached Memcached的Client方法介绍 Python-memcached的基本使用 python memcached 邮件列表","tags":[{"name":"memcache","slug":"memcache","permalink":"http://keleir.github.io/tags/memcache/"}]}]